{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time \n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.tripadvisor.com\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "CHROME_DRIVER = \"./chromedriver-win64/chromedriver.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make restaurants list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## class: RestaurantListGetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is for getting the list of restaurants which satisfy the following conditions:\n",
    "- located in Zurich\n",
    "- offers dinner\n",
    "- offers Swiss dishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestaurantListGetter():\n",
    "    def __init__(self):\n",
    "        self.rank_list = []\n",
    "        self.name_list = []\n",
    "        self.html_list = []   \n",
    "    \n",
    "    def addInfo(self, offset):        \n",
    "        # set url and params\n",
    "        url = \"https://www.tripadvisor.com/RestaurantSearch\"\n",
    "        params = {\n",
    "            \"Action\": \"PAGE\",\n",
    "            \"ajax\": \"1\",\n",
    "            \"availSearchEnabled\": \"true\",\n",
    "            \"sortOrder\": \"relevance\",\n",
    "            \"geo\": \"188113\",\n",
    "            \"itags\": \"10591,16556\",\n",
    "            \"cat\": \"10628\",\n",
    "            \"zfp\": \"10599\",\n",
    "            \"eaterydate\": \"2023_10_01\",\n",
    "            \"date\": \"2023-10-02\",\n",
    "            \"time\": \"20:00:00\",\n",
    "            \"people\": \"2\",\n",
    "            \"o\": offset\n",
    "        }\n",
    "        \n",
    "        # request url\n",
    "        try:\n",
    "            r = requests.get(url, params=params, headers=HEADERS, timeout=10)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        # add info\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        \n",
    "        # html,rank,name\n",
    "        a_tags = soup.find_all(\"a\", class_=\"Lwqic Cj b\")\n",
    "        self.html_list += [a_tag.get(\"href\") for a_tag in a_tags]\n",
    "        text_list = [a_tag.get_text(strip=True).split('.', 1) for a_tag in a_tags]\n",
    "        self.rank_list += [int(text[0]) if len(text)==2 else 0 for text in text_list]\n",
    "        self.name_list += [text[1] if len(text)==2 else text[0] for text in text_list]\n",
    "       \n",
    "        \n",
    "    def makeDataFrame(self):\n",
    "        for i in range(10):\n",
    "            offset = \"a\"+str(30*i)\n",
    "            self.addInfo(offset)\n",
    "            time.sleep(1)\n",
    "            \n",
    "        self.df = pd.DataFrame({\n",
    "            \"rank\": self.rank_list,\n",
    "            \"name\": self.name_list,\n",
    "            \"html\": self.html_list\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## make restaurants list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = RestaurantListGetter()\n",
    "rl.makeDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.df.to_csv(\"./restaurantList.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get html files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## class: HtmlGetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is for getting html files of each restaurant using selenium library.  \n",
    "Note:\n",
    "- Make sure that webdriver (chrome driver) is located in CHROME_DRIVER folder, which is defined the top of this notebook.\n",
    "- Html files will be saved in \"html\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HtmlGetter():\n",
    "    def __init__(self, url, driver):\n",
    "        self.url = url\n",
    "        self.driver = driver\n",
    "        self.restaurantId = self.getRestaurantId()\n",
    "        self.relativeUrl = self.url.replace(BASE_URL, \"\")\n",
    "        self.hasNextPage = True\n",
    "        self.soup = None\n",
    "        \n",
    "        \n",
    "    def getRestaurantId(self):\n",
    "        pattern = re.compile(r'-d(\\d+)-')\n",
    "        match = pattern.search(self.url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def saveAllHtml(self):\n",
    "        while self.hasNextPage:\n",
    "            self.saveEachHtml()\n",
    "            self.checkNextPage()         \n",
    "    \n",
    "    \n",
    "    def saveEachHtml(self):\n",
    "        # access url\n",
    "        self.driver.get(self.url)\n",
    "        self.driver.refresh()\n",
    "        \n",
    "        # wait to avoid overload for server\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # click \"More\" to show full text        \n",
    "        more_links = self.driver.find_elements_by_css_selector('span.taLnk.ulBlueLinks')\n",
    "        if len(more_links)>0:\n",
    "            more_links[0].click()\n",
    "        \n",
    "        # wait to avoid overload for server\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # extract review part\n",
    "        self.soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        reviews = self.soup.find(id=\"taplc_location_reviews_list_resp_rr_resp_0\")\n",
    "        \n",
    "        # delete img link\n",
    "        for img_tag in reviews.find_all(\"img\"):\n",
    "            img_tag.decompose()\n",
    "        \n",
    "        # save html\n",
    "        dir_path = f\"./html/{self.restaurantId}\"\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        filename = f\"{dir_path}/{self.relativeUrl}\"\n",
    "        with open(filename, \"w\", encoding=\"utf_8_sig\") as f:\n",
    "             f.write(reviews.prettify())\n",
    "        \n",
    "        # check if next page exists\n",
    "        self.checkNextPage()\n",
    "    \n",
    "    \n",
    "    def checkNextPage(self):\n",
    "        next_button = self.soup.find(\"a\", class_=\"nav next ui_button primary\")\n",
    "        if (not next_button) or (next_button.get('href')==\"\"):\n",
    "            self.hasNextPage = False\n",
    "        else:\n",
    "            self.relativeUrl = next_button.get('href')\n",
    "            self.url = BASE_URL + self.relativeUrl   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load restaurants list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get html list of restaurants\n",
    "rl = pd.read_csv(\"./restaurantList.csv\")\n",
    "html_list = list(rl[\"html\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set web driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options, executable_path=CHROME_DRIVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 11/11"
     ]
    }
   ],
   "source": [
    "# iterate over restaurants\n",
    "for i, html in enumerate(html_list):\n",
    "    # set url\n",
    "    url = BASE_URL + html\n",
    "    \n",
    "    # scraping all review pages\n",
    "    hg = HtmlGetter(url, driver)\n",
    "    hg.saveAllHtml()\n",
    "    \n",
    "    # display progress\n",
    "    total = len(html_list)\n",
    "    print(f\"\\rDone: {i+1}/{total}\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quit web driver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
